import os
import os.path as osp
import random
import glob
from tkinter.tix import Tree

import torch
from tqdm import tqdm
import networkx as nx
from networkx.algorithms.isomorphism import GraphMatcher
from python_graphs import program_graph
from torch_geometric.data import Dataset
from typing import Optional, Callable, List

from codescholar.utils.graph_utils import save_as_json, program_graph_to_nx
from codescholar.utils.train_utils import sample_neigh, batch_nx_graphs, get_device


def load_dataset(name):
    """load a dataset from disk
    """
    train, test = [], []

    if name == "test":
        dataset = [g for g in nx.graph_atlas_g()[1:] if nx.is_connected(g)]
    else:
        dataset = ProgramDataset(root=f"./tmp/{name}", name=name)
    
    dataset = list(dataset)
    random.shuffle(dataset)

    train_len = int(0.8 * len(dataset))
    for i, graph in tqdm(enumerate(dataset), total=len(dataset)):
        if i < train_len:
            train.append(graph)
        else:
            test.append(graph)
    
    return train, test


class Corpus:
    """Generator for graphs saved in a dataset file to train models.

    Iteratively, new batch of graphs (positive and negative)
    are generated by sampling from the dataset
    """
    def __init__(self, dataset, node_anchored, min_size=2, max_size=30):
        self.node_anchored = node_anchored
        self.dataset = load_dataset(dataset)
        self.min_size = min_size
        self.max_size = max_size

    def gen_data_loaders(self, size, batch_size):
        loaders = [[batch_size] * (size // batch_size) for i in range(3)]
        return loaders
    
    def gen_batch(
        self, batch_target, batch_neg_target,
        batch_neg_query, train
    ):
        # CONFIGS:
        max_size = 5
        min_size = 4
        seed = None
        filter_negs = False
        # sample_method = "tree-pair"

        # set datapoints
        batch_size = batch_target  # BUG??
        train_set, test_set = self.dataset
        graphs = train_set if train else test_set

        if seed is not None:
            random.seed(seed)
        
        # Get positive examples
        pos_t, pos_q = [], []
        pos_t_anchors, pos_q_anchors = [], []

        for _ in range(batch_size // 2):
            size = random.randint(min_size + 1, max_size)
            
            # choose target: perform a random bfs
            graph, t = sample_neigh(graphs, size)

            # choose query: a random (but anchored) subgraph of target
            q = t[:random.randint(min_size, len(t) - 1)]
                
            if self.node_anchored:
                anchor = list(graph.nodes)[0]
                pos_t_anchors.append(anchor)
                pos_q_anchors.append(anchor)

            neigh_t, neigh_q = graph.subgraph(t), graph.subgraph(q)
            pos_t.append(neigh_t)
            pos_q.append(neigh_q)
        
        # Get negative examples
        neg_t, neg_q = [], []
        neg_t_anchors, neg_q_anchors = [], []

        while len(neg_t) < batch_size // 2:
            size = random.randint(min_size + 1, max_size)
            
            # choose different target and query
            graph_t, t = sample_neigh(graphs, size)
            graph_q, q = sample_neigh(
                graphs, random.randint(min_size, size - 1))

            if self.node_anchored:
                neg_t_anchors.append(list(graph_t.nodes)[0])
                neg_q_anchors.append(list(graph_q.nodes)[0])
            
            neigh_t, neigh_q = graph_t.subgraph(t), graph_q.subgraph(q)

            if filter_negs:
                matcher = GraphMatcher(neigh_t, neigh_q)
                # a <= b (b is subgraph of a)
                if matcher.subgraph_is_isomorphic():
                    continue
            
            neg_t.append(neigh_t)
            neg_q.append(neigh_q)

        def process_examples(graphs, anchors):
            examples = batch_nx_graphs(
                graphs, anchors=anchors if
                self.node_anchored else None)

            return examples

        pos_t = process_examples(pos_t, pos_t_anchors).to(get_device())
        pos_q = process_examples(pos_q, pos_q_anchors).to(get_device())
        neg_t = process_examples(neg_t, neg_t_anchors).to(get_device())
        neg_q = process_examples(neg_q, neg_q_anchors).to(get_device())
                
        return pos_t, pos_q, neg_t, neg_q


# Ref: https://pytorch-geometric.readthedocs.io/en/latest/_modules/
# torch_geometric/datasets/tu_dataset.html#TUDataset
class ProgramDataset(Dataset):
    def __init__(
        self,
        root: str,
        name: str,
        transform: Optional[Callable] = None,
        pre_transform: Optional[Callable] = None,
        pre_filter: Optional[Callable] = None,
        save_json: Optional[bool] = False
    ):
        self.name = name
        self.save_json = save_json
        self.json_dir = osp.join(root, 'networkx')
        super().__init__(root, transform, pre_transform, pre_filter)
    
    def download(self):
        pass

    @property
    def num_node_labels(self) -> int:
        return self.sizes['num_node_labels']

    @property
    def num_node_attributes(self) -> int:
        return self.sizes['num_node_attributes']

    @property
    def num_edge_labels(self) -> int:
        return self.sizes['num_edge_labels']

    @property
    def num_edge_attributes(self) -> int:
        return self.sizes['num_edge_attributes']
    
    @property
    def raw_file_names(self) -> List[str]:
        names = sorted(glob.glob(osp.join(self.raw_dir, '*.py')))
        names = [os.path.basename(file) for file in names]
        return names

    @property
    def processed_file_names(self) -> str:
        names = sorted(glob.glob(osp.join(self.processed_dir, '*.pt')))
        names = [os.path.basename(file) for file in names]
        return 'not_implemented.pt'

    def pre_transform(self, data):
        return data
    
    def process(self):
        """process and store python graphs as a Data object onto the disk
        """
        idx = 0

        for raw_path in self.raw_paths:
            data = self.create_prog_datapoint(raw_path)

            if self.pre_filter is not None and self.prefilter(data):
                continue

            if self.pre_transform is not None:
                data = self.pre_transform(data)

            if self.save_json is True:
                save_as_json(data, osp.join(self.json_dir, f'data_{idx}.json'))

            torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))
            idx += 1

    def create_prog_datapoint(self, path):
        prog_graph = program_graph.get_program_graph(path)
        digraph = program_graph_to_nx(prog_graph, directed=True)

        return digraph
    
    def len(self):
        return len(self.raw_file_names)
    
    def get(self, idx):
        """load a python method (graph) from disk.
        """
        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))
        return data
