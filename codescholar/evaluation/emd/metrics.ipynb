{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_RESULTS_PATH = os.path.join(\"../gpt\", \"results\", \"2023-07-03\")\n",
    "CS_RESULTS_PATH = os.path.join(\"../results\", \"2023-07-04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of files per directory in GPT_RESULTS_PATH\n",
    "gpt_idiom_counts = {}\n",
    "cs_idiom_counts = {}\n",
    "\n",
    "# for each library in GPT_RESULTS_PATH\n",
    "for dir in os.listdir(GPT_RESULTS_PATH):\n",
    "    for subdir in os.listdir(os.path.join(GPT_RESULTS_PATH, dir)):\n",
    "        gpt_idiom_counts[subdir] = len(os.listdir(os.path.join(GPT_RESULTS_PATH, dir, subdir)))\n",
    "\n",
    "# sort counts by api (key)\n",
    "gpt_idiom_counts = {k: v for k, v in sorted(gpt_idiom_counts.items(), key=lambda item: item[0])}\n",
    "\n",
    "# for each library in CS_RESULTS_PATH\n",
    "for dir in os.listdir(CS_RESULTS_PATH):\n",
    "    if not os.path.isdir(os.path.join(CS_RESULTS_PATH, dir)):\n",
    "        continue\n",
    "\n",
    "    for subdir in os.listdir(os.path.join(CS_RESULTS_PATH, dir)):\n",
    "        if cs_idiom_counts.get(subdir, None) is None:\n",
    "            cs_idiom_counts[subdir] = 0\n",
    "\n",
    "        for file in os.listdir(os.path.join(CS_RESULTS_PATH, dir, subdir, \"idioms\", \"progs\")):\n",
    "            _, size, cluster, nhood_count, hole = file.split(\"_\")\n",
    "            hole = hole.split(\".\")[0]\n",
    "\n",
    "            if int(hole) == 0 and int(nhood_count) > 0:\n",
    "                cs_idiom_counts[subdir] = cs_idiom_counts.get(subdir, 0) + 1\n",
    "\n",
    "# sort counts by api (key)\n",
    "cs_idiom_counts = {k: v for k, v in sorted(cs_idiom_counts.items(), key=lambda item: item[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.bar(cs_idiom_counts.keys(), cs_idiom_counts.values(), label=\"CodeScholar\")\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.xlabel(\"API\")\n",
    "# plt.ylabel(\"Number of idioms\")\n",
    "# plt.title(\"Number of idioms per API\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.bar(gpt_idiom_counts.keys(), gpt_idiom_counts.values(), label=\"GPT-3\")\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.xlabel(\"API\")\n",
    "# plt.ylabel(\"Number of idioms\")\n",
    "# plt.title(\"Number of idioms per API\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and parse /emd/emd.log file\n",
    "# the format is:\n",
    "# ========== [pandas: pd.read_csv] ==========\n",
    "# Programs: 20000\n",
    "# CS idioms: 149\n",
    "# GPT idioms: 8\n",
    "# Random idioms: 10\n",
    "# CS EMD: 0.40105256416916146\n",
    "# GPT EMD: 0.4697192690205559\n",
    "# Random EMD: 0.4489479035710553\n",
    "# =====================================\n",
    "\n",
    "import regex as re\n",
    "\n",
    "\n",
    "def parse_emd_log(logs):\n",
    "    emd = {}\n",
    "\n",
    "    logs = re.findall(\n",
    "        r\"========== \\[(.+): (.+)\\] ==========\\nPrograms: (.+)\\nCS idioms: (.+)\\nGPT idioms: (.+)\\nRandom idioms: (.+)\\nCS EMD: (.+)\\nGPT EMD: (.+)\\nRandom EMD: (.+)\\n=====================================\",\n",
    "        logs,\n",
    "    )\n",
    "    for log in logs:\n",
    "        lib, api, n_progs, n_cs_idioms, n_gpt_idioms, n_rand_idioms, cs_emd, gpt_emd, rand_emd = log\n",
    "        emd[lib] = emd.get(lib, {})\n",
    "        emd[lib][api] = (float(cs_emd), float(gpt_emd), float(rand_emd))\n",
    "\n",
    "    return emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd = parse_emd_log(open(os.path.join(\"../emd\", \"emd.single.result\")).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pandas', 'numpy', 'os', 'sklearn', 'matplotlib', 'torch'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pandas', 'numpy', 'os', 'sklearn', 'matplotlib', 'torch']\n",
      "[0.3958083827801948, 0.4454906900131255, 0.42249569537148246, 0.34591476259962783, 0.3778598258208419, 0.35508324619462783]\n",
      "[0.4626735489715698, 0.5188748104768457, 0.4973094433083336, 0.4487554271372074, 0.44957474155123683, 0.47480430686455793]\n",
      "[0.4501101558725966, 0.4982254780190106, 0.49790619287662324, 0.44881009700113594, 0.4193334408839467, 0.38672776583364393]\n"
     ]
    }
   ],
   "source": [
    "# averages per library\n",
    "print(list(emd.keys()))\n",
    "avg_cs_emd_lib = [np.mean([x[0] for x in emd[lib].values()]) for lib in emd]\n",
    "avg_gpt_emd_lib = [np.mean([x[1] for x in emd[lib].values()]) for lib in emd]\n",
    "avg_random_emd_lib = [np.mean([x[2] for x in emd[lib].values()]) for lib in emd]\n",
    "\n",
    "print(avg_cs_emd_lib)\n",
    "print(avg_gpt_emd_lib)\n",
    "print(avg_random_emd_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39044210046331673, 0.4753320463849586, 0.45018552174782617)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall averages\n",
    "np.mean(avg_cs_emd_lib), np.mean(avg_gpt_emd_lib), np.mean(avg_random_emd_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_emd = parse_emd_log(open(os.path.join(\"../emd\", \"emd.multi.result\")).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pairs', 'mixpairs', 'triplets']\n",
      "[0.45090168404697223, 0.46902650682675545, 0.46512558713657565]\n",
      "[0.5183084022576386, 0.5316574641163595, 0.5246211114152105]\n",
      "[0.48588109059481643, 0.47140997601739915, 0.48647951108040993]\n"
     ]
    }
   ],
   "source": [
    "# averages per type\n",
    "print(list(multi_emd.keys()))\n",
    "avg_cs_emd_lib = [np.mean([x[0] for x in multi_emd[type].values()]) for type in multi_emd]\n",
    "avg_gpt_emd_lib = [np.mean([x[1] for x in multi_emd[type].values()]) for type in multi_emd]\n",
    "avg_random_emd_lib = [np.mean([x[2] for x in multi_emd[type].values()]) for type in multi_emd]\n",
    "print(avg_cs_emd_lib)\n",
    "print(avg_gpt_emd_lib)\n",
    "print(avg_random_emd_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46168459267010115, 0.5248623259297363, 0.4812568592308752)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall averages\n",
    "np.mean(avg_cs_emd_lib), np.mean(avg_gpt_emd_lib), np.mean(avg_random_emd_lib)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scholarenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
