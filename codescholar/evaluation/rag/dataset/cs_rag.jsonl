{"task_id": 18079563, "prompt": "def f_18079563(s1, s2):\n\treturn ", "suffix": "", "canonical_solution": "pd.Series(list(set(s1).intersection(set(s2))))", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    x1, x2 = pd.Series([1,2]), pd.Series([1,3])\n    assert candidate(x1, x2).equals(pd.Series([1]))\n", "\n    x1, x2 = pd.Series([1,2]), pd.Series([1,3, 10, 4, 5, 9])\n    assert candidate(x1, x2).equals(pd.Series([1]))\n", "\n    x1, x2 = pd.Series([1,2]), pd.Series([1,2, 10])\n    assert candidate(x1, x2).equals(pd.Series([1, 2]))\n"], "entry_point": "f_18079563", "intent": "find intersection data between series `s1` and series `s2`", "library": "pandas", "api": "s1.intersection"}
{"task_id": 13567345, "prompt": "def f_13567345(a):\n\treturn ", "suffix": "", "canonical_solution": "a.sum(axis=1)", "test_start": "\nimport numpy as np \n\ndef check(candidate):", "test": ["\n    a1 = np.array([[i for i in range(3)] for j in range(5)])\n    assert np.array_equal(candidate(a1), np.array([3, 3, 3, 3, 3]))\n", "\n    a2 = np.array([[i+j for i in range(3)] for j in range(5)])\n    assert np.array_equal(candidate(a2), np.array([ 3,  6,  9, 12, 15]))\n", "\n    a3 = np.array([[i*j for i in range(3)] for j in range(5)])\n    assert np.array_equal(candidate(a3), np.array([ 0,  3,  6,  9, 12]))\n"], "entry_point": "f_13567345", "intent": "Calculate sum over all rows of 2D numpy array `a`", "library": "numpy", "api": "np.sum"}
{"task_id": 41861705, "prompt": "def f_41861705(split_df, csv_df):\n\treturn ", "suffix": "", "canonical_solution": "pd.merge(split_df, csv_df, on=['key'], suffixes=('_left', '_right'))", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    split_df = pd.DataFrame({'key': ['foo', 'bar'], 'value': [1, 2]})\n    csv_df = pd.DataFrame({'key': ['foo', 'baz'], 'value': [3, 4]})\n    result = pd.DataFrame({'key': ['foo'], 'value_left': [1],'value_right': [3]})\n    assert all(candidate(csv_df, split_df) == result)\n"], "entry_point": "f_41861705", "intent": "Create new DataFrame object by merging columns \"key\" of  dataframes `split_df` and `csv_df` and rename the columns from dataframes `split_df` and `csv_df` with suffix `_left` and `_right` respectively", "library": "pandas", "api": "pd.merge"}
{"task_id": 4490961, "prompt": "def f_4490961(P, T):\n\treturn ", "suffix": "", "canonical_solution": "scipy.tensordot(P, T, axes=[1, 1]).swapaxes(0, 1)", "test_start": "\nimport scipy\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    P = np.array([[6, 2, 7], [1, 1, 8], [8, 7, 1], [9, 6, 4], [2, 1, 1]])\n    T = np.array([[[9, 7, 2, 3], [9, 6, 8, 2], [6, 6, 2, 8]],\n                  [[4, 5, 5, 3], [1, 8, 3, 5], [2, 8, 1, 6]]])\n    result = np.array([[[114,  96,  42,  78], [ 66,  61,  26,  69], [141, 104,  74,  46], [159, 123,  74,  71],  [ 33,  26,  14,  16]], \n                      [[ 40, 102,  43,  70], [ 21,  77,  16,  56], [ 41, 104,  62,  65], [ 50, 125,  67,  81], [ 11,  26,  14,  17]]])\n    assert np.array_equal(candidate(P, T), result)\n"], "entry_point": "f_4490961", "intent": "Multiply a matrix `P` with a 3d tensor `T` in scipy", "library": "numpy", "api": "np.matmul"}
{"task_id": 2173087, "prompt": "def f_2173087():\n\treturn ", "suffix": "", "canonical_solution": "numpy.zeros((3, 3, 3))", "test_start": "\nimport numpy \nimport numpy as np\n\ndef check(candidate):", "test": ["\n    result = np.array([[[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]],\n                          [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]],\n                          [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]])\n    assert np.array_equal(candidate(), result)\n"], "entry_point": "f_2173087", "intent": "Create 3d array of zeroes of size `(3,3,3)`", "library": "numpy", "api": "np.zeros"}
{"task_id": 30385151, "prompt": "def f_30385151(x):\n\t", "suffix": "\n\treturn x", "canonical_solution": "x = np.asarray(x).reshape(1, -1)[(0), :]", "test_start": "\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    assert all(candidate(1.) == np.asarray(1.))\n", "\n    assert all(candidate(123) == np.asarray(123))\n", "\n    assert all(candidate('a') == np.asarray('a'))\n", "\n    assert all(candidate(False) == np.asarray(False))\n"], "entry_point": "f_30385151", "intent": "convert scalar `x` to array", "library": "numpy", "api": "np.array"}
{"task_id": 28742436, "prompt": "def f_28742436():\n\treturn ", "suffix": "", "canonical_solution": "np.maximum([2, 3, 4], [1, 5, 2])", "test_start": "\nimport numpy as np \n\ndef check(candidate):", "test": ["\n    assert all(candidate() == np.array([2, 5, 4]))\n"], "entry_point": "f_28742436", "intent": "create array containing the maximum value of respective elements of array `[2, 3, 4]` and array `[1, 5, 2]`", "library": "numpy", "api": "np.maximum"}
{"task_id": 15325182, "prompt": "def f_15325182(df):\n\treturn ", "suffix": "", "canonical_solution": "df.b.str.contains('^f')", "test_start": "\nimport pandas as pd \n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([[1, 'fat'], [2, 'hip'], [3, 'foo']], columns = ['a', 'b'])\n    expected = [True, False, True]\n    actual = candidate(df)\n    for i in range (0, len(expected)):\n        assert expected[i] == actual[i]\n"], "entry_point": "f_15325182", "intent": "filter rows in pandas starting with alphabet 'f' using regular expression.", "library": "pandas", "api": "df.filter"}
{"task_id": 38535931, "prompt": "def f_38535931(df, tuples):\n\treturn ", "suffix": "", "canonical_solution": "df.set_index(list('BC')).drop(tuples, errors='ignore').reset_index()", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([[3, 4], [4, 5], [-1, -2]], columns = ['B', 'C'])\n    tuples = [(3, 4), (-1, -2)]\n    expected = pd.DataFrame([[4, 5]], columns = ['B', 'C'])\n    actual = candidate(df, tuples)\n    assert pd.DataFrame.equals(actual, expected)\n"], "entry_point": "f_38535931", "intent": "pandas: delete rows in dataframe `df` based on multiple columns values", "library": "pandas", "api": "df.drop"}
{"task_id": 26053849, "prompt": "def f_26053849(df):\n\treturn ", "suffix": "", "canonical_solution": "df.astype(bool).sum(axis=1)", "test_start": "\nimport pandas as pd \n\ndef check(candidate):", "test": ["\n    df1 = pd.DataFrame([[0,0,0], [0,1,0], [1,1,1]])\n    assert candidate(df1).to_list() == [0, 1, 3]\n", "\n    df2 = pd.DataFrame([[0,0,0], [0,2,0], [1,10,8.9]])\n    assert candidate(df1).to_list() == [0, 1, 3]\n", "\n    df2 = pd.DataFrame([[0,0.0,0], [0,2.0,0], [1,10,8.9]])\n    assert candidate(df1).to_list() == [0, 1, 3]\n", "\n    df = df = pd.DataFrame([[4, 0, 0], [1, 0, 1]])\n    expected = [1, 2]\n    actual = candidate(df)\n    for i in range(0, len(expected)):\n        assert expected[i] == actual[i]\n"], "entry_point": "f_26053849", "intent": "count non zero values in each column in pandas data frame `df`", "library": "pandas", "api": "df.astype(bool).sum"}
{"task_id": 17138464, "prompt": "def f_17138464(x, y):\n\treturn ", "suffix": "", "canonical_solution": "plt.plot(x, y, label='H\\u2082O')", "test_start": "\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef check(candidate):", "test": ["\n    pic = candidate(np.array([1,2,3]),np.array([4,5,6]))[0]\n    assert pic.get_label() == 'H\u2082O'\n    x, y = pic.get_data()\n    assert all(x == np.array([1,2,3]))\n    assert all(y == np.array([4,5,6]))\n", "\n    pic = candidate(np.array([6, 7, 899]),np.array([0, 1, 245]))[0]\n    assert pic.get_label() == 'H\u2082O'\n    x, y = pic.get_data()\n    assert all(x == np.array([6, 7, 899]))\n    assert all(y == np.array([0, 1, 245]))\n"], "entry_point": "f_17138464", "intent": "subscript text 'H20' with '2' as subscripted in matplotlib labels for arrays 'x' and 'y'.", "library": "matplotlib", "api": "plt.xlabel"}
{"task_id": 17138464, "prompt": "def f_17138464(x, y):\n\treturn ", "suffix": "", "canonical_solution": "plt.plot(x, y, label='$H_2O$')", "test_start": "\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef check(candidate):", "test": ["\n    pic = candidate(np.array([1,2,3]),np.array([4,5,6]))[0]\n    assert pic.get_label() == '$H_2O$'\n    x, y = pic.get_data()\n    assert all(x == np.array([1,2,3]))\n    assert all(y == np.array([4,5,6]))\n", "\n    pic = candidate(np.array([6, 7, 899]),np.array([0, 1, 245]))[0]\n    assert pic.get_label() == '$H_2O$'\n    x, y = pic.get_data()\n    assert all(x == np.array([6, 7, 899]))\n    assert all(y == np.array([0, 1, 245]))\n"], "entry_point": "f_17138464", "intent": "subscript text 'H20' with '2' as subscripted in matplotlib labels for arrays 'x' and 'y'.", "library": "matplotlib", "api": "plt.xlabel"}
{"task_id": 13793321, "prompt": "def f_13793321(df1, df2):\n\treturn ", "suffix": "", "canonical_solution": "df1.merge(df2, on='Date_Time')", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df1 = pd.DataFrame([[1, 2, 3]], columns=[\"Date\", \"Time\", \"Date_Time\"])\n    df2 = pd.DataFrame([[1, 3],[4, 9]], columns=[\"Name\", \"Date_Time\"])\n    assert candidate(df1, df2).to_dict() == {'Date': {0: 1}, 'Time': {0: 2}, 'Date_Time': {0: 3}, 'Name': {0: 1}}\n"], "entry_point": "f_13793321", "intent": "joining data from dataframe `df1` with data from dataframe `df2` based on matching values of column 'Date_Time' in both dataframes", "library": "pandas", "api": "pd.merge"}
{"task_id": 273192, "prompt": "def f_273192(directory):\n\t", "suffix": "\n\treturn ", "canonical_solution": "if (not os.path.exists(directory)):\n\t    os.makedirs(directory)", "test_start": "\nimport os \n\ndef check(candidate):", "test": ["\n    candidate(\"hello\")\n    assert os.path.exists(\"hello\")\n", "\n    candidate(\"_some_dir\")\n    assert os.path.exists(\"_some_dir\")\n"], "entry_point": "f_273192", "intent": "check if directory `directory ` exists and create it if necessary", "library": "os", "api": "os.path.exists"}
{"task_id": 273192, "prompt": "def f_273192(path):\n\t", "suffix": "\n\treturn ", "canonical_solution": "try:\n\t    os.makedirs(path)\n\texcept OSError:\n\t    if (not os.path.isdir(path)):\n\t        raise", "test_start": "\nimport os \n\ndef check(candidate):", "test": ["\n    candidate(\"hello\")\n    assert os.path.exists(\"hello\")\n", "\n    candidate(\"_some_dir\")\n    assert os.path.exists(\"_some_dir\")\n"], "entry_point": "f_273192", "intent": "check if a directory `path` exists and create it if necessary", "library": "os", "api": "os.path.exists"}
{"task_id": 273192, "prompt": "def f_273192(path):\n\t", "suffix": "\n\treturn ", "canonical_solution": "try:\n\t    os.makedirs(path)\n\texcept OSError as exception:\n\t    if (exception.errno != errno.EEXIST):\n\t        raise", "test_start": "\nimport os \n\ndef check(candidate):", "test": ["\n    candidate(\"hello\")\n    assert os.path.exists(\"hello\")\n", "\n    candidate(\"_some_dir\")\n    assert os.path.exists(\"_some_dir\")\n"], "entry_point": "f_273192", "intent": "check if a directory `path` exists and create it if necessary", "library": "os", "api": "os.path.exists"}
{"task_id": 20180210, "prompt": "def f_20180210(A, B):\n\treturn ", "suffix": "", "canonical_solution": "np.concatenate((A, B))", "test_start": "\nimport numpy as np \n\ndef check(candidate):", "test": ["\n    A = np.array([1,2])\n    B = np.array([3,4])\n    assert np.allclose(candidate(A, B), np.array([1,2,3,4]))\n", "\n    A = np.array([[1,2]])\n    B = np.array([[3,4]])\n    assert np.allclose(candidate(A, B), np.array([[1,2],[3,4]]))\n", "\n    A = np.array([[1],[2]])\n    B = np.array([[3],[4]])\n    assert np.allclose(candidate(A, B), np.array([[1],[2],[3],[4]]))\n", "\n    a = np.array([[1, 3, 4], [4, 5, 6], [6, 0, -1]])\n    b = np.array([[5, 6, 1], [0, 2, -1], [9, 4, 1]])\n    expected = np.array([[ 1, 3, 4], [ 4, 5, 6],\n        [ 6, 0, -1], [ 5, 6, 1], [ 0, 2, -1], [ 9, 4, 1]])\n    assert np.array_equal(candidate(a, b), expected)\n"], "entry_point": "f_20180210", "intent": "Create new matrix object  by concatenating data from matrix A and matrix B", "library": "numpy", "api": "np.concatenate"}
{"task_id": 20180210, "prompt": "def f_20180210(A, B):\n\treturn ", "suffix": "", "canonical_solution": "np.vstack((A, B))", "test_start": "\nimport numpy as np \n\ndef check(candidate):", "test": ["\n    A = np.array([1,2])\n    B = np.array([3,4])\n    assert np.allclose(candidate(A, B), np.array([[1,2],[3,4]]))\n", "\n    A = np.array([[1,2]])\n    B = np.array([[3,4]])\n    assert np.allclose(candidate(A, B), np.array([[1,2],[3,4]]))\n", "\n    A = np.array([[1],[2]])\n    B = np.array([[3],[4]])\n    assert np.allclose(candidate(A, B), np.array([[1],[2],[3],[4]]))\n", "\n    a = np.array([[1, 3, 4], [4, 5, 6], [6, 0, -1]])\n    b = np.array([[5, 6, 1], [0, 2, -1], [9, 4, 1]])\n    expected = np.array([[ 1, 3, 4], [ 4, 5, 6],\n        [ 6, 0, -1], [ 5, 6, 1], [ 0, 2, -1], [ 9, 4, 1]])\n    assert np.array_equal(candidate(a, b), expected)\n"], "entry_point": "f_20180210", "intent": "concat two matrices `A` and `B` in numpy", "library": "numpy", "api": "np.concatenate"}
{"task_id": 2011048, "prompt": "def f_2011048(filepath):\n\treturn ", "suffix": "", "canonical_solution": "os.stat(filepath).st_size", "test_start": "\nimport os\n\ndef check(candidate):", "test": ["\n    with open(\"tmp.txt\", 'w') as fw: fw.write(\"hello world!\")\n    assert candidate(\"tmp.txt\") == 12\n", "\n    with open(\"tmp.txt\", 'w') as fw: fw.write(\"\")\n    assert candidate(\"tmp.txt\") == 0\n", "\n    with open(\"tmp.txt\", 'w') as fw: fw.write('\\n')\n    assert candidate(\"tmp.txt\") == 1\n", "\n    filename = 'o.txt'\n    with open (filename, 'w') as f:\n        f.write('a')\n    assert candidate(filename) == 1\n"], "entry_point": "f_2011048", "intent": "Get the characters count in a file `filepath`", "library": "os", "api": "os.path.getsize"}
{"task_id": 17315881, "prompt": "def f_17315881(df):\n\treturn ", "suffix": "", "canonical_solution": "all(df.index[:-1] <= df.index[1:])", "test_start": "\nimport pandas as pd \n\ndef check(candidate):", "test": ["\n    df1 = pd.DataFrame({'a': [1,2], 'bb': [0,2]})\n    assert candidate(df1) == True\n", "\n    df2 = pd.DataFrame({'a': [1,2,3,4,5], 'bb': [0,3,5,7,9]})\n    shuffled = df2.sample(frac=3, replace=True)\n    assert candidate(shuffled) == False\n", "\n    df = pd.DataFrame([[1, 2], [5, 4]], columns=['a', 'b'])\n    assert candidate(df)\n"], "entry_point": "f_17315881", "intent": "check if a pandas dataframe `df`'s index is sorted", "library": "pandas", "api": "df.index.is_monotonic"}
{"task_id": 21800169, "prompt": "def f_21800169(df):\n\treturn ", "suffix": "", "canonical_solution": "df.loc[df['BoolCol']]", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([[True, 2, 3], [False, 5, 6]], columns = ['BoolCol', 'a', 'b'])\n    y = candidate(df)\n    assert y['a'][0] == 2\n    assert y['b'][0] == 3\n"], "entry_point": "f_21800169", "intent": "get index of rows in column 'BoolCol'", "library": "pandas", "api": "df[df['BoolCol']].index"}
{"task_id": 21800169, "prompt": "def f_21800169(df):\n\treturn ", "suffix": "", "canonical_solution": "df.iloc[np.flatnonzero(df['BoolCol'])]", "test_start": "\nimport numpy as np\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([[True, 2, 3], [False, 5, 6]], columns = ['BoolCol', 'a', 'b'])\n    y = candidate(df)\n    assert y['a'][0] == 2\n    assert y['b'][0] == 3\n"], "entry_point": "f_21800169", "intent": "Create a list containing the indexes of rows where the value of column 'BoolCol' in dataframe `df` are equal to True", "library": "pandas", "api": "df[df['BoolCol'] == True].index.tolist()"}
{"task_id": 21800169, "prompt": "def f_21800169(df):\n\treturn ", "suffix": "", "canonical_solution": "df[df['BoolCol'] == True].index.tolist()", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([[True, 2, 3], [False, 5, 6]], columns = ['BoolCol', 'a', 'b'])\n    y = candidate(df)\n    assert y == [0]\n"], "entry_point": "f_21800169", "intent": "from dataframe `df` get list of indexes of rows where column 'BoolCol' values match True", "library": "pandas", "api": "df[df['BoolCol']].index.tolist()"}
{"task_id": 21800169, "prompt": "def f_21800169(df):\n\treturn ", "suffix": "", "canonical_solution": "df[df['BoolCol']].index.tolist()", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([[True, 2, 3], [False, 5, 6]], columns = ['BoolCol', 'a', 'b'])\n    y = candidate(df)\n    assert y == [0]\n"], "entry_point": "f_21800169", "intent": "get index of rows in dataframe `df` which column 'BoolCol' matches value True", "library": "pandas", "api": "df[df['BoolCol'] == True].index"}
{"task_id": 299446, "prompt": "def f_299446(owd):\n\t", "suffix": "\n\treturn ", "canonical_solution": "os.chdir(owd)", "test_start": "\nimport os\nfrom unittest.mock import Mock\n\ndef check(candidate):", "test": ["\n    os.chdir = Mock()\n    try:\n        candidate('/')\n    except:\n        assert False\n"], "entry_point": "f_299446", "intent": "change working directory to the directory `owd`", "library": "os", "api": "os.chdir"}
{"task_id": 4143502, "prompt": "def f_4143502():\n\treturn ", "suffix": "", "canonical_solution": "plt.scatter(np.random.randn(100), np.random.randn(100), facecolors='none')", "test_start": "\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef check(candidate):", "test": ["\n    assert 'matplotlib' in str(type(candidate()))\n"], "entry_point": "f_4143502", "intent": "scatter a plot with x, y position of `np.random.randn(100)` and face color equal to none", "library": "matplotlib", "api": "plt.scatter"}
{"task_id": 4143502, "prompt": "def f_4143502():\n\treturn ", "suffix": "", "canonical_solution": "plt.plot(np.random.randn(100), np.random.randn(100), 'o', mfc='none')", "test_start": "\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef check(candidate):", "test": ["\n    assert 'matplotlib' in str(type(candidate()[0]))\n"], "entry_point": "f_4143502", "intent": "do a scatter plot with empty circles", "library": "matplotlib", "api": "plt.scatter"}
{"task_id": 27975069, "prompt": "def f_27975069(df):\n\treturn ", "suffix": "", "canonical_solution": "df[df['ids'].str.contains('ball')]", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    f = pd.DataFrame([[\"ball1\", 1, 2], [\"hall\", 5, 4]], columns = ['ids', 'x', 'y'])\n    f1 = candidate(f)\n    assert f1['x'][0] == 1\n    assert f1['y'][0] == 2\n"], "entry_point": "f_27975069", "intent": "filter rows of datafram `df` containing key word `ball` in column `ids`", "library": "pandas", "api": "df.str.contains"}
{"task_id": 20461165, "prompt": "def f_20461165(df):\n\treturn ", "suffix": "", "canonical_solution": "df.reset_index(level=0, inplace=True)", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([[384, 593], [781, 123]], columns = ['gi', 'ptt_loc'])\n    candidate(df)\n    assert df['index'][0] == 0\n    assert df['index'][1] == 1\n"], "entry_point": "f_20461165", "intent": "convert index at level 0 into a column in dataframe `df`", "library": "pandas", "api": "df.reset_index"}
{"task_id": 20461165, "prompt": "def f_20461165(df):\n\treturn ", "suffix": "", "canonical_solution": "df.reset_index(level=['tick', 'obs'])", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([['2016-09-13', 'C', 2, 0.0139], ['2016-07-17', 'A', 2, 0.5577]], columns = ['tick', 'tag', 'obs', 'val'])\n    df = df.set_index(['tick', 'tag', 'obs'])\n    df = candidate(df)\n    assert df['tick']['C'] == '2016-09-13'\n"], "entry_point": "f_20461165", "intent": "convert pandas index in a dataframe `df` to columns", "library": "pandas", "api": "df.reset_index"}
{"task_id": 678236, "prompt": "def f_678236():\n\treturn ", "suffix": "", "canonical_solution": "os.path.splitext(os.path.basename('hemanth.txt'))[0]", "test_start": "\nimport os \n\ndef check(candidate):", "test": ["\n    assert candidate() == \"hemanth\"\n"], "entry_point": "f_678236", "intent": "get the filename without the extension from file 'hemanth.txt'", "library": "os", "api": "os.path.splitext"}
{"task_id": 25698710, "prompt": "def f_25698710(df):\n\treturn ", "suffix": "", "canonical_solution": "df.replace({'\\n': '<br>'}, regex=True)", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame(['klm\\npqr', 'wxy\\njkl'], columns = ['val'])\n    expected = pd.DataFrame(['klm<br>pqr', 'wxy<br>jkl'], columns = ['val'])\n    assert pd.DataFrame.equals(candidate(df), expected)\n"], "entry_point": "f_25698710", "intent": "replace all occurences of newlines `\\n` with `<br>` in dataframe `df`", "library": "pandas", "api": "df.replace"}
{"task_id": 36674519, "prompt": "def f_36674519():\n\treturn ", "suffix": "", "canonical_solution": "pd.date_range('2016-01-01', freq='WOM-2FRI', periods=13)", "test_start": "\nimport pandas as pd\nimport datetime\n\ndef check(candidate):", "test": ["\n    actual = candidate() \n    expected = [[2016, 1, 8], [2016, 2, 12],\n                [2016, 3, 11], [2016, 4, 8],\n                [2016, 5, 13], [2016, 6, 10],\n                [2016, 7, 8], [2016, 8, 12],\n                [2016, 9, 9], [2016, 10, 14],\n                [2016, 11, 11], [2016, 12, 9],\n                [2017, 1, 13]]\n    for i in range(0, len(expected)):\n        d = datetime.date(expected[i][0], expected[i][1], expected[i][2])\n        assert d == actual[i].date()\n"], "entry_point": "f_36674519", "intent": "create a DatetimeIndex containing 13 periods of the second friday of each month starting from date '2016-01-01'", "library": "pandas", "api": "pd.date_range"}
{"task_id": 4444923, "prompt": "def f_4444923(filename):\n\treturn ", "suffix": "", "canonical_solution": "os.path.splitext(filename)[0]", "test_start": "\nimport os\n\ndef check(candidate):", "test": ["\n    assert candidate('/Users/test/hello.txt') == '/Users/test/hello'\n", "\n    assert candidate('hello.txt') == 'hello'\n", "\n    assert candidate('hello') == 'hello'\n", "\n    assert candidate('.gitignore') == '.gitignore'\n"], "entry_point": "f_4444923", "intent": "get filename without extension from file `filename`", "library": "os", "api": "os.path.splitext"}
{"task_id": 20546419, "prompt": "def f_20546419(r):\n\treturn ", "suffix": "", "canonical_solution": "np.random.shuffle(np.transpose(r))", "test_start": "\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    a1 = np.array([[ 1, 20], [ 2, 30]])\n    candidate(a1)\n    assert np.array_equal(a1, np.array([[ 1, 20],[ 2, 30]])) or np.array_equal(a1, np.array([[ 20, 1], [ 30, 2]]))\n", "\n    a2 = np.array([[ 1], [ 2]])\n    candidate(a2)                       \n    assert np.array_equal(a2,np.array([[ 1], [ 2]]) )\n", "\n    a3 = np.array([[ 1,2,3]])\n    candidate(a3)\n    assert np.array_equal(a3,np.array([[ 1,2,3]])) or np.array_equal(a3,np.array([[ 2,1,3]]))           or np.array_equal(a3,np.array([[ 1,3,2]]))            or np.array_equal(a3,np.array([[3,2,1]])) or np.array_equal(a3,np.array([[3,1,2]]))            or np.array_equal(a3,np.array([[2,3,1]])) \n", "\n    a4 = np.zeros(shape=(5,2))\n    candidate(a4)\n    assert np.array_equal(a4, np.zeros(shape=(5,2)))\n"], "entry_point": "f_20546419", "intent": "shuffle columns of an numpy array 'r'", "library": "numpy", "api": "np.random.shuffle"}
{"task_id": 574236, "prompt": "def f_574236():\n\treturn ", "suffix": "", "canonical_solution": "os.statvfs('/').f_files - os.statvfs('/').f_ffree", "test_start": "\nimport os \n\ndef check(candidate):", "test": ["\n    assert candidate() == (os.statvfs('/').f_files - os.statvfs('/').f_ffree)\n"], "entry_point": "f_574236", "intent": "determine number of files on a drive with python", "library": "os", "api": "os.listdir"}
{"task_id": 40903174, "prompt": "def f_40903174(df):\n\treturn ", "suffix": "", "canonical_solution": "df.sort_values(['System_num', 'Dis'])", "test_start": "\nimport pandas as pd \n\ndef check(candidate):", "test": ["\n    df1 = pd.DataFrame([[6, 1, 1], [5, 1, 1], [4, 1, 1], [3, 2, 1], [2, 2, 1], [1, 2, 1]], columns = ['Dis', 'System_num', 'Energy'])\n    df_ans1 = pd.DataFrame([[4, 1, 1], [5, 1, 1], [6, 1, 1], [1, 2, 1], [2, 2, 1], [3, 2, 1]], columns = ['Dis', 'System_num', 'Energy'])\n    assert (df_ans1.equals(candidate(df1).reset_index(drop = True))) == True\n", "\n    df2 = pd.DataFrame([[6, 3, 1], [5, 2, 1], [4, 1, 1]], columns = ['Dis', 'System_num', 'Energy'])\n    df_ans2 = pd.DataFrame([[4, 1, 1], [5, 2, 1], [6, 3, 1]], columns = ['Dis', 'System_num', 'Energy'])\n    assert (df_ans2.equals(candidate(df2).reset_index(drop = True))) == True\n", "\n    df3 = pd.DataFrame([[1, 3, 1], [3, 3, 1], [2, 3, 1], [6, 1, 1], [4, 1, 1], [5, 2, 1], [3, 2, 1]], columns = ['Dis', 'System_num', 'Energy'])\n    df_ans3 = pd.DataFrame([[4, 1,1], [6, 1, 1], [3, 2, 1], [5, 2, 1], [1, 3, 1], [2, 3, 1], [3, 3, 1]], columns = ['Dis', 'System_num', 'Energy'])\n    assert (df_ans3.equals(candidate(df3).reset_index(drop = True))) == True \n", "\n    df4 = pd.DataFrame([[1, 2, 3], [1, 2, 3], [4, 1, 3]], columns = ['Dis', 'System_num', 'Energy'])\n    df_ans4 = pd.DataFrame([[1, 2, 3], [1, 2, 3], [4, 1, 3]])\n    assert (df_ans4.equals(candidate(df4).reset_index(drop = True))) == False\n"], "entry_point": "f_40903174", "intent": "Sorting data in Pandas DataFrame `df` with columns 'System_num' and 'Dis'", "library": "pandas", "api": "df.sort_values"}
{"task_id": 34945274, "prompt": "def f_34945274(A):\n\treturn ", "suffix": "", "canonical_solution": "np.where(np.in1d(A, [1, 3, 4]).reshape(A.shape), A, 0)", "test_start": "\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    A = np.array([[6, 8, 1, 3, 4], [-1, 0, 3, 5, 1]])\n    B = np.array([[0, 0, 1, 3, 4], [0, 0, 3, 0, 1]])\n    assert np.array_equal(candidate(A), B)\n"], "entry_point": "f_34945274", "intent": "replace all elements in array `A` that are not present in array `[1, 3, 4]` with zeros", "library": "numpy", "api": "np.where"}
{"task_id": 15819980, "prompt": "def f_15819980(a):\n\treturn ", "suffix": "", "canonical_solution": "np.mean(a, axis=1)", "test_start": "\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    A = np.array([[6, 8, 1, 3, 4], [-1, 0, 3, 5, 1]])\n    B = np.array([4.4, 1.6])\n    assert np.array_equal(candidate(A), B)\n"], "entry_point": "f_15819980", "intent": "calculate mean across dimension in a 2d array `a`", "library": "numpy", "api": "np.mean"}
{"task_id": 33058590, "prompt": "def f_33058590(df):\n\treturn ", "suffix": "", "canonical_solution": "df.fillna(df.mean(axis=0))", "test_start": "\nimport pandas as pd\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([[1,2,3],[4,5,6],[7.0,np.nan,9.0]], columns=[\"c1\",\"c2\",\"c3\"]) \n    res = pd.DataFrame([[1,2,3],[4,5,6],[7.0,3.5,9.0]], columns=[\"c1\",\"c2\",\"c3\"])\n    assert candidate(df).equals(res)\n"], "entry_point": "f_33058590", "intent": "replacing nan in the dataframe `df` with row average", "library": "pandas", "api": "df.fillna"}
{"task_id": 23359886, "prompt": "def f_23359886(a):\n\treturn ", "suffix": "", "canonical_solution": "a[np.where((a[:, (0)] == 0) * (a[:, (1)] == 1))]", "test_start": "\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    a = np.array([[ 0,  1,  2], [ 3,  4,  5], [ 6,  7,  8], [ 9, 10, 11], [12, 13, 14]])\n    res = np.array([[0, 1, 2]])\n    assert np.array_equal(candidate(a), res)\n"], "entry_point": "f_23359886", "intent": "selecting rows in Numpy ndarray 'a', where the value in the first column is 0 and value in the second column is 1", "library": "numpy", "api": "np.where"}
{"task_id": 8577137, "prompt": "def f_8577137():\n\treturn ", "suffix": "", "canonical_solution": "open('path/to/FILE_NAME.ext', 'w')", "test_start": "\nimport os\n\ndef check(candidate):", "test": ["\n    path1 = os.path.join(\"\", \"path\")\n    os.mkdir(path1)\n    path2 = os.path.join(\"path\", \"to\")\n    os.mkdir(path2)\n    candidate()\n    assert os.path.exists('path/to/FILE_NAME.ext')\n"], "entry_point": "f_8577137", "intent": "Open a file `path/to/FILE_NAME.ext` in write mode", "library": "os", "api": "os.path.join"}
{"task_id": 17926273, "prompt": "def f_17926273(df):\n\treturn ", "suffix": "", "canonical_solution": "df.groupby(['col1', 'col2'])['col3'].nunique().reset_index()", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    data = [[1, 1, 1], [1, 1, 1], [1, 1, 2], [1, 2, 3], [1, 2, 3], [1, 2, 3], \n            [2, 1, 1], [2, 1, 2], [2, 1, 3], [2, 2, 3], [2, 2, 3], [2, 2, 3]]\n    expected = [[1, 1, 2], [1, 2, 1], [2, 1, 3], [2, 2, 1]]\n    df = pd.DataFrame(data, columns = ['col1', 'col2', 'col3'])\n    expected_df = pd.DataFrame(expected, columns = ['col1', 'col2', 'col3'])\n    df1 = candidate(df)\n    assert pd.DataFrame.equals(expected_df, df1)\n"], "entry_point": "f_17926273", "intent": "count distinct values in a column 'col3' of a pandas dataframe `df` group by objects in 'col1' and 'col2'", "library": "pandas", "api": "df.groupby"}
{"task_id": 26097916, "prompt": "def f_26097916(sf):\n\t", "suffix": "\n\treturn df", "canonical_solution": "df = pd.DataFrame({'email': sf.index, 'list': sf.values})", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    dict = {'email1': [1.0, 5.0, 7.0], 'email2': [4.2, 3.6, -0.9]}\n    sf = pd.Series(dict)\n    k = [['email1', [1.0, 5.0, 7.0]], ['email2', [4.2, 3.6, -0.9]]]\n    df1 = pd.DataFrame(k, columns=['email', 'list'])\n    df2 = candidate(sf)\n    assert pd.DataFrame.equals(df1, df2)\n"], "entry_point": "f_26097916", "intent": "convert a pandas series `sf` into a pandas dataframe `df` with columns `email` and `list`", "library": "pandas", "api": "pd.DataFrame"}
{"task_id": 24189150, "prompt": "def f_24189150(df, engine):\n\t", "suffix": "\n\treturn ", "canonical_solution": "df.to_sql('test', engine)", "test_start": "\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\ndef check(candidate):", "test": ["\n    engine = create_engine('sqlite://', echo=False)\n    df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n    candidate(df, engine)\n    result = pd.read_sql('SELECT name FROM test', engine)\n    assert result.equals(df)\n"], "entry_point": "f_24189150", "intent": "write records in dataframe `df` to table 'test' in schema 'a_schema' with `engine`", "library": "pandas", "api": "df.to_sql"}
{"task_id": 28986489, "prompt": "def f_28986489(df):\n\t", "suffix": "\n\treturn df", "canonical_solution": "df['range'].replace(',', '-', inplace=True)", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame({'range' : [\",\", \"(50,290)\", \",,,\"]})\n    res = pd.DataFrame({'range' : [\"-\", \"(50,290)\", \",,,\"]})\n    assert candidate(df).equals(res)\n"], "entry_point": "f_28986489", "intent": "replace a characters in a column of a dataframe `df`", "library": "pandas", "api": "df.replace"}
{"task_id": 29836836, "prompt": "def f_29836836(df):\n\treturn ", "suffix": "", "canonical_solution": "df.groupby('A').filter(lambda x: len(x) > 1)", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    assert candidate(pd.DataFrame([[1, 2], [1, 4], [5, 6]], columns=['A', 'B'])).equals(pd.DataFrame([[1, 2], [1, 4]], columns=['A', 'B'])) is True\n", "\n    assert candidate(pd.DataFrame([[1, 2], [1, 4], [1, 6]], columns=['A', 'B'])).equals(pd.DataFrame([[1, 2], [1, 4], [1, 6]], columns=['A', 'B'])) is True\n"], "entry_point": "f_29836836", "intent": "filter dataframe `df` by values in column `A` that appear more than once", "library": "pandas", "api": "df.duplicated"}
{"task_id": 35420052, "prompt": "def f_35420052(plt, mappable, ax3):\n\t", "suffix": "\n\treturn plt", "canonical_solution": "plt.colorbar(mappable=mappable, cax=ax3)", "test_start": "\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom obspy.core.trace import Trace\nfrom obspy.imaging.spectrogram import spectrogram\n\ndef check(candidate):", "test": ["\n    spl1 = Trace(data=np.arange(0, 10))\n    fig = plt.figure()\n    ax1 = fig.add_axes([0.1, 0.75, 0.7, 0.2]) #[left bottom width height]\n    ax2 = fig.add_axes([0.1, 0.1, 0.7, 0.60], sharex=ax1)\n    ax3 = fig.add_axes([0.83, 0.1, 0.03, 0.6])\n\n    #make time vector\n    t = np.arange(spl1.stats.npts) / spl1.stats.sampling_rate\n\n    #plot waveform (top subfigure)    \n    ax1.plot(t, spl1.data, 'k')\n\n    #plot spectrogram (bottom subfigure)\n    spl2 = spl1\n    fig = spl2.spectrogram(show=False, axes=ax2, wlen=10)\n    mappable = ax2.images[0]\n    candidate(plt, mappable, ax3)\n    \n    im=ax2.images\n    assert im[-1].colorbar is not None\n"], "entry_point": "f_35420052", "intent": "add color bar with image `mappable` to plot `plt`", "library": "matplotlib", "api": "plt.colorbar"}
{"task_id": 29903025, "prompt": "def f_29903025(df):\n\treturn ", "suffix": "", "canonical_solution": "Counter(' '.join(df['text']).split()).most_common(100)", "test_start": "\nimport pandas as pd\nfrom collections import Counter\n \ndef check(candidate):", "test": ["\n    df = pd.DataFrame({\"text\": [\n      'Python is a high-level, general-purpose programming language.', \n      'Its design philosophy emphasizes code readability with the use of significant indentation. Python is dynamically-typed and garbage-collected.'\n    ]})\n    assert candidate(df) == [('Python', 2),('is', 2),('a', 1),('high-level,', 1),('general-purpose', 1),\n        ('programming', 1),('language.', 1),('Its', 1),('design', 1),('philosophy', 1),('emphasizes', 1),\n        ('code', 1),('readability', 1),('with', 1), ('the', 1),('use', 1),('of', 1),('significant', 1),\n        ('indentation.', 1),('dynamically-typed', 1),('and', 1),('garbage-collected.', 1)]\n"], "entry_point": "f_29903025", "intent": "count most frequent 100 words in column 'text' of dataframe `df`", "library": "pandas", "api": "df.value_counts"}
{"task_id": 14401047, "prompt": "def f_14401047(data):\n\treturn ", "suffix": "", "canonical_solution": "data.mean(axis=1).reshape(data.shape[0], -1)", "test_start": "\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    data = np.array([[1, 2, 3, 4, 4, 3, 7, 1], [6, 2, 3, 4, 3, 4, 4, 1]])\n    expected_res = np.array([[3.125], [3.375]])\n    assert np.array_equal(candidate(data), expected_res)\n"], "entry_point": "f_14401047", "intent": "average each two columns of array `data`", "library": "numpy", "api": "np.mean"}
{"task_id": 9938130, "prompt": "def f_9938130(df):\n\treturn ", "suffix": "", "canonical_solution": "df.plot(kind='barh', stacked=True)", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    data = [[1, 3], [2, 5], [4, 8]]\n    df = pd.DataFrame(data, columns = ['a', 'b'])\n    assert str(candidate(df)).split('(')[0] == 'AxesSubplot'\n"], "entry_point": "f_9938130", "intent": "plotting stacked barplots on a panda data frame `df`", "library": "matplotlib", "api": "plt.bar"}
{"task_id": 22799300, "prompt": "def f_22799300(out):\n\treturn ", "suffix": "", "canonical_solution": "pd.DataFrame(out.tolist(), columns=['out-1', 'out-2'], index=out.index)", "test_start": "\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame(dict(x=np.random.randn(100), y=np.repeat(list(\"abcd\"), 25)))\n    out = df.groupby(\"y\").x.apply(stats.ttest_1samp, 0)\n    test = pd.DataFrame(out.tolist())\n    test.columns = ['out-1', 'out-2']\n    test.index = out.index\n    res = candidate(out)\n    assert(test.equals(res))\n"], "entry_point": "f_22799300", "intent": "unpack a series of tuples in pandas `out` into a DataFrame with column names 'out-1' and 'out-2'", "library": "pandas", "api": "pd.DataFrame"}
{"task_id": 3464359, "prompt": "def f_3464359(ax, labels):\n\treturn ", "suffix": "", "canonical_solution": "ax.set_xticklabels(labels, rotation=45)", "test_start": "\nimport matplotlib.pyplot as plt \n\ndef check(candidate):", "test": ["\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3, 4], [1, 4, 2, 3])\n    ret = candidate(ax, [f\"#{i}\" for i in range(7)])\n    assert [tt.get_rotation() == 45.0 for tt in ret]\n"], "entry_point": "f_3464359", "intent": "rotate the xtick `labels` of matplotlib plot `ax` by `45` degrees to make long labels readable", "library": "matplotlib", "api": "ax.set_xticklabels"}
{"task_id": 15247628, "prompt": "def f_15247628(x):\n\treturn ", "suffix": "", "canonical_solution": "x['name'][x.duplicated('name')]", "test_start": "\nimport pandas as pd \n\ndef check(candidate): ", "test": ["\n    assert candidate(pd.DataFrame([{'name': 'willy', 'age': 10}, {'name': 'wilson', 'age': 11}, {'name': 'zoe', 'age': 10}])).tolist() == [] \n", "\n    assert candidate(pd.DataFrame([{'name': 'willy', 'age': 10}, {'name': 'willy', 'age': 11}, {'name': 'zoe', 'age': 10}])).tolist() == ['willy'] \n", "\n    assert candidate(pd.DataFrame([{'name': 'willy', 'age': 11}, {'name': 'willy', 'age': 11}, {'name': 'zoe', 'age': 10}])).tolist() == ['willy'] \n", "\n    assert candidate(pd.DataFrame([{'name': 'Willy', 'age': 11}, {'name': 'willy', 'age': 11}, {'name': 'zoe', 'age': 10}])).tolist() == []\n"], "entry_point": "f_15247628", "intent": "find duplicate names in column 'name' of the dataframe `x`", "library": "pandas", "api": "df.duplicated"}
{"task_id": 29394552, "prompt": "def f_29394552(ax):\n\t", "suffix": "\n\treturn ", "canonical_solution": "ax.set_rlabel_position(135)", "test_start": "\nimport matplotlib.pyplot as plt \n\ndef check(candidate): ", "test": ["\n    ax = plt.subplot(111, polar=True)\n    candidate(ax)\n    assert ax.properties()['rlabel_position'] == 135.0\n"], "entry_point": "f_29394552", "intent": "place the radial ticks in plot `ax` at 135 degrees", "library": "matplotlib", "api": "ax.set_rticks"}
{"task_id": 3320406, "prompt": "def f_3320406(my_path):\n\treturn ", "suffix": "", "canonical_solution": "os.path.isabs(my_path)", "test_start": "\nimport os\n\ndef check(candidate): ", "test": ["\n    assert candidate('.') == False \n", "\n    assert candidate('/') == True \n", "\n    assert candidate('/usr') == True\n"], "entry_point": "f_3320406", "intent": "check if path `my_path` is an absolute path", "library": "os", "api": "os.path.isabs"}
{"task_id": 20067636, "prompt": "def f_20067636(df):\n\treturn ", "suffix": "", "canonical_solution": "df.groupby('id').first()", "test_start": "\nimport pandas as pd \n\ndef check(candidate): ", "test": ["\n    df = pd.DataFrame({\n        'id': [1, 1, 1, 2, 2, 3, 3, 3, 3, 4, 4, 5, 6, 6, 6, 7, 7], \n        'value': ['first', 'second', 'second', 'first', 'second', 'first', 'third', 'fourth', 'fifth', 'second', 'fifth', 'first', 'first', 'second', 'third', 'fourth', 'fifth']\n    })\n    assert candidate(df).to_dict() == {'value': {1: 'first', 2: 'first', 3: 'first', 4: 'second', 5: 'first', 6: 'first', 7: 'fourth'}}\n"], "entry_point": "f_20067636", "intent": "pandas dataframe `df` get first row of each group by 'id'", "library": "pandas", "api": "df.groupby"}
{"task_id": 40924332, "prompt": "def f_40924332(df):\n\treturn ", "suffix": "", "canonical_solution": "pd.concat([df[0].apply(pd.Series), df[1]], axis=1)", "test_start": "\nimport numpy as np\nimport pandas as pd \n\ndef check(callerFunction):", "test": ["\n    assert callerFunction(pd.DataFrame([[[8, 10, 12], 'A'], [[7, 9, 11], 'B']])).equals(pd.DataFrame([[8,10,12,'A'], [7,9,11,'B']], columns=[0,1,2,1]))\n", "\n    assert callerFunction(pd.DataFrame([[[8, 10, 12], 'A'], [[7, 11], 'B']])).equals(pd.DataFrame([[8.0,10.0,12.0,'A'], [7.0,11.0,np.nan,'B']], columns=[0,1,2,1]))\n", "\n    assert callerFunction(pd.DataFrame([[[8, 10, 12]], [[7, 9, 11], 'B']])).equals(pd.DataFrame([[8,10,12,None], [7,9,11,'B']], columns=[0,1,2,1]))\n"], "entry_point": "f_40924332", "intent": "split a list in first column into multiple columns keeping other columns as well in pandas data frame `df`", "library": "pandas", "api": "df.str.split"}
{"task_id": 18897261, "prompt": "def f_18897261(df):\n\treturn ", "suffix": "", "canonical_solution": "df['group'].plot(kind='bar', color=['r', 'g', 'b', 'r', 'g', 'b', 'r'])", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([1, 3, 4, 5, 7, 9], columns = ['group'])\n    a = candidate(df)\n    assert 'AxesSubplot' in str(type(a))\n"], "entry_point": "f_18897261", "intent": "make a barplot of data in column `group` of dataframe `df` colour-coded according to list `color`", "library": "matplotlib", "api": "plt.bar"}
{"task_id": 303200, "prompt": "def f_303200():\n\t", "suffix": "\n\treturn ", "canonical_solution": "shutil.rmtree('/folder_name')", "test_start": "\nimport os\nimport shutil\nfrom unittest.mock import Mock\n\ndef check(candidate):", "test": ["\n    shutil.rmtree = Mock()\n    os.walk = Mock(return_value = [])\n    candidate()\n    assert os.walk('/') == []\n"], "entry_point": "f_303200", "intent": "remove directory tree '/folder_name'", "library": "os", "api": "os.rmdir"}
{"task_id": 9775297, "prompt": "def f_9775297(a, b):\n\treturn ", "suffix": "", "canonical_solution": "np.vstack((a, b))", "test_start": "\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    a = np.array([[1, 2, 3], [4, 5, 6]])\n    b = np.array([[9, 8, 7], [6, 5, 4]])\n    assert np.array_equal(candidate(a, b), np.array([[1, 2, 3], [4, 5, 6], [9, 8, 7], [6, 5, 4]]))\n", "\n    a = np.array([[1, 2.45, 3], [4, 0.55, 612]])\n    b = np.array([[988, 8, 7], [6, 512, 4]])\n    assert np.array_equal(candidate(a, b), np.array([[1, 2.45, 3], [4, 0.55, 612], [988, 8, 7], [6, 512, 4]]))\n"], "entry_point": "f_9775297", "intent": "append a numpy array 'b' to a numpy array 'a'", "library": "numpy", "api": "np.append"}
{"task_id": 21887754, "prompt": "def f_21887754(a, b):\n\treturn ", "suffix": "", "canonical_solution": "np.concatenate((a, b), axis=0)", "test_start": "\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    a = np.array([[1, 5, 9], [2, 6, 10]])\n    b = np.array([[3, 7, 11], [4, 8, 12]])\n    assert np.array_equal(candidate(a, b), np.array([[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]))\n", "\n    a = np.array([[1, 2.45, 3], [4, 0.55, 612]])\n    b = np.array([[988, 8, 7], [6, 512, 4]])\n    assert np.array_equal(candidate(a, b), np.array([[1, 2.45, 3], [4, 0.55, 612], [988, 8, 7], [6, 512, 4]]))\n"], "entry_point": "f_21887754", "intent": "numpy concatenate two arrays `a` and `b` along the first axis", "library": "numpy", "api": "np.concatenate"}
{"task_id": 21887754, "prompt": "def f_21887754(a, b):\n\treturn ", "suffix": "", "canonical_solution": "np.concatenate((a, b), axis=1)", "test_start": "\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    a = np.array([[1, 5, 9], [2, 6, 10]])\n    b = np.array([[3, 7, 11], [4, 8, 12]])\n    assert np.array_equal(candidate(a, b), np.array([[1, 5, 9, 3, 7, 11], [2, 6, 10, 4, 8, 12]]))\n", "\n    a = np.array([[1, 2.45, 3], [4, 0.55, 612]])\n    b = np.array([[988, 8, 7], [6, 512, 4]])\n    assert np.array_equal(candidate(a, b), np.array([[1, 2.45, 3, 988, 8, 7], [4, 0.55, 612, 6, 512, 4]]))\n"], "entry_point": "f_21887754", "intent": "numpy concatenate two arrays `a` and `b` along the second axis", "library": "numpy", "api": "np.concatenate"}
{"task_id": 21887754, "prompt": "def f_21887754(a, b):\n\treturn ", "suffix": "", "canonical_solution": "np.r_[(a[None, :], b[None, :])]", "test_start": "\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    a = np.array([[1, 5, 9], [2, 6, 10]])\n    b = np.array([[3, 7, 11], [4, 8, 12]])\n    assert np.array_equal(candidate(a, b), np.array([[[1, 5, 9], [2, 6, 10]], [[3, 7, 11], [4, 8, 12]]]))\n", "\n    a = np.array([[1, 2.45, 3], [4, 0.55, 612]])\n    b = np.array([[988, 8, 7], [6, 512, 4]])\n    assert np.array_equal(candidate(a, b), np.array([[[1, 2.45, 3], [4, 0.55, 612]], [[988, 8 , 7], [6, 512, 4]]]))\n"], "entry_point": "f_21887754", "intent": "numpy concatenate two arrays `a` and `b` along the first axis", "library": "numpy", "api": "np.concatenate"}
{"task_id": 21887754, "prompt": "def f_21887754(a, b):\n\treturn ", "suffix": "", "canonical_solution": "np.array((a, b))", "test_start": "\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    a = np.array([[1, 5, 9], [2, 6, 10]])\n    b = np.array([[3, 7, 11], [4, 8, 12]])\n    assert np.array_equal(candidate(a, b), np.array([[[1, 5, 9], [2, 6, 10]], [[3, 7, 11], [4, 8, 12]]]))\n", "\n    a = np.array([[1, 2.45, 3], [4, 0.55, 612]])\n    b = np.array([[988, 8, 7], [6, 512, 4]])\n    assert np.array_equal(candidate(a, b), np.array([[[1, 2.45, 3], [4, 0.55, 612]], [[988, 8 , 7], [6, 512, 4]]]))\n"], "entry_point": "f_21887754", "intent": "numpy concatenate two arrays `a` and `b` along the first axis", "library": "numpy", "api": "np.concatenate"}
{"task_id": 17552997, "prompt": "def f_17552997(df):\n\treturn ", "suffix": "", "canonical_solution": "df.xs('sat', level='day', drop_level=False)", "test_start": "\nimport pandas as pd \n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame({'year':[2008,2008,2008,2008,2009,2009,2009,2009], \n                      'flavour':['strawberry','strawberry','banana','banana',\n                      'strawberry','strawberry','banana','banana'],\n                      'day':['sat','sun','sat','sun','sat','sun','sat','sun'],\n                      'sales':[10,12,22,23,11,13,23,24]})\n    df = df.set_index(['year','flavour','day'])\n    assert candidate(df).to_dict() == {'sales': {(2008, 'strawberry', 'sat'): 10, (2008, 'banana', 'sat'): 22, (2009, 'strawberry', 'sat'): 11, (2009, 'banana', 'sat'): 23}}\n"], "entry_point": "f_17552997", "intent": "add a column 'day' with value 'sat' to dataframe `df`", "library": "pandas", "api": "df['day'] = 'sat'"}
{"task_id": 10960463, "prompt": "def f_10960463():\n\treturn ", "suffix": "", "canonical_solution": "matplotlib.rc('font', **{'sans-serif': 'Arial', 'family': 'sans-serif'})", "test_start": "\nimport matplotlib\n\ndef check(candidate):", "test": ["\n    try:\n        candidate()\n    except:\n        assert False\n"], "entry_point": "f_10960463", "intent": "set font `Arial` to display non-ascii characters in matplotlib", "library": "matplotlib", "api": "plt.rcParams"}
{"task_id": 20576618, "prompt": "def f_20576618(df):\n\treturn ", "suffix": "", "canonical_solution": "df['date'].apply(lambda x: x.toordinal())", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame(\n        {\n            \"group\": [\"A\", \"A\", \"A\", \"A\", \"A\"],\n            \"date\": pd.to_datetime([\"2020-01-02\", \"2020-01-13\", \"2020-02-01\", \"2020-02-23\", \"2020-03-05\"]),\n            \"value\": [10, 20, 16, 31, 56],\n        })    \n    data_series = candidate(df).tolist()\n    assert data_series[1] == 737437\n", "\n    df = pd.DataFrame(\n        {\n            \"group\": [\"A\", \"A\", \"A\", \"A\", \"A\"],\n            \"date\": pd.to_datetime([\"2020-01-02\", \"2020-01-13\", \"2020-02-01\", \"2020-02-23\", \"2020-03-05\"]),\n            \"value\": [10, 20, 16, 31, 56],\n        })    \n    data_series = candidate(df).tolist()\n    assert data_series[1] == 737437\n"], "entry_point": "f_20576618", "intent": "Convert  DateTime column 'date' of pandas dataframe 'df' to ordinal", "library": "pandas", "api": "df['date'].toordinal"}
{"task_id": 31793195, "prompt": "def f_31793195(df):\n\treturn ", "suffix": "", "canonical_solution": "df.index.get_loc('bob')", "test_start": "\nimport pandas as pd\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame(data=np.asarray([[1,2,3],[4,5,6],[7,8,9]]), index=['alice', 'bob', 'charlie'])\n    index = candidate(df)\n    assert index == 1\n"], "entry_point": "f_31793195", "intent": "Get the integer location of a key `bob` in a pandas data frame `df`", "library": "pandas", "api": "df.index.get_loc"}
{"task_id": 40144769, "prompt": "def f_40144769(df):\n\treturn ", "suffix": "", "canonical_solution": "df[df.columns[-1]]", "test_start": "\nimport pandas as pd \n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([[1, 2, 3],[4,5,6]], columns=[\"a\", \"b\", \"c\"])\n    assert candidate(df).tolist() == [3,6]\n", "\n    df = pd.DataFrame([[\"Hello\", \"world!\"],[\"Hi\", \"world!\"]], columns=[\"a\", \"b\"])\n    assert candidate(df).tolist() == [\"world!\", \"world!\"]\n"], "entry_point": "f_40144769", "intent": "select the last column of dataframe `df`", "library": "pandas", "api": "df.iloc"}
{"task_id": 30787901, "prompt": "def f_30787901(df):\n\treturn ", "suffix": "", "canonical_solution": "df.loc[df['Letters'] == 'C', 'Letters'].values[0]", "test_start": "\nimport pandas as pd \n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([[\"a\", 1],[\"C\", 6]], columns=[\"Letters\", \"Numbers\"])\n    assert candidate(df) == 'C'\n", "\n    df = pd.DataFrame([[None, 1],[\"C\", 789]], columns=[\"Letters\", \"Names\"])\n    assert candidate(df) == 'C'\n"], "entry_point": "f_30787901", "intent": "get the first value from dataframe `df` where column 'Letters' is equal to 'C'", "library": "pandas", "api": "df.loc"}
{"task_id": 18730044, "prompt": "def f_18730044():\n\treturn ", "suffix": "", "canonical_solution": "np.column_stack(([1, 2, 3], [4, 5, 6]))", "test_start": "\nimport numpy as np \n\ndef check(candidate):", "test": ["\n    assert np.all(candidate() == np.array([[1, 4], [2, 5], [3, 6]]))\n"], "entry_point": "f_18730044", "intent": "converting two lists `[1, 2, 3]` and `[4, 5, 6]` into a matrix", "library": "numpy", "api": "np.array"}
{"task_id": 13413590, "prompt": "def f_13413590(df):\n\treturn ", "suffix": "", "canonical_solution": "df.dropna(subset=[1])", "test_start": "\nimport numpy as np\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    data = {0:[3.0, 4.0, 2.0], 1:[2.0, 3.0, np.nan], 2:[np.nan, 3.0, np.nan]}\n    df = pd.DataFrame(data)\n    d = {0:[3.0, 4.0], 1:[2.0, 3.0], 2:[np.nan, 3.0]}\n    res = pd.DataFrame(d)\n    assert candidate(df).equals(res)\n"], "entry_point": "f_13413590", "intent": "Drop rows of pandas dataframe `df` having NaN in column at index \"1\"", "library": "pandas", "api": "df.dropna"}
{"task_id": 3964681, "prompt": "def f_3964681():\n\t", "suffix": "\n\treturn files", "canonical_solution": "\n\tos.chdir('/mydir')\n\tfiles = [] \n\tfor file in glob.glob('*.txt'):\n\t\tfiles.append(file)\n", "test_start": "\nimport os\nimport glob\nfrom unittest.mock import Mock\n\ndef check(candidate):", "test": ["\n    samples = ['abc.txt']\n    os.chdir = Mock()\n    glob.glob = Mock(return_value = samples)\n    assert candidate() == samples\n"], "entry_point": "f_3964681", "intent": "Find all files `files` in directory '/mydir' with extension '.txt'", "library": "os", "api": "os.listdir"}
{"task_id": 3964681, "prompt": "def f_3964681():\n\treturn ", "suffix": "", "canonical_solution": "[file for file in os.listdir('/mydir') if file.endswith('.txt')]", "test_start": "\nimport os\nfrom unittest.mock import Mock\n\ndef check(candidate):", "test": ["\n    samples = ['abc.txt', 'f.csv']\n    os.listdir = Mock(return_value = samples)\n    assert candidate() == ['abc.txt']\n"], "entry_point": "f_3964681", "intent": "Find all files in directory \"/mydir\" with extension \".txt\"", "library": "os", "api": "os.listdir"}
{"task_id": 3964681, "prompt": "def f_3964681():\n\treturn ", "suffix": "", "canonical_solution": "[file for (root, dirs, files) in os.walk('/mydir') for file in files if file.endswith('.txt')]", "test_start": "\nimport os\nfrom unittest.mock import Mock\n\ndef check(candidate):", "test": ["\n    name = '/mydir'\n    samples = [(name, [], ['abc.txt', 'f.csv'])]\n    os.walk = Mock(return_value = samples)\n    assert candidate() == ['abc.txt']\n"], "entry_point": "f_3964681", "intent": "Find all files in directory \"/mydir\" with extension \".txt\"", "library": "os", "api": "os.listdir"}
{"task_id": 20865487, "prompt": "def f_20865487(df):\n\treturn ", "suffix": "", "canonical_solution": "df.plot(legend=False)", "test_start": "\nimport os \nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([1, 2, 3, 4, 5], columns = ['Vals'])\n    res = candidate(df)\n    assert 'AxesSubplot' in str(type(res))\n    assert res.legend_ is None\n"], "entry_point": "f_20865487", "intent": "plot dataframe `df` without a legend", "library": "pandas", "api": "df.plot"}
{"task_id": 6375343, "prompt": "def f_6375343():\n\t", "suffix": "\n\treturn arr", "canonical_solution": "arr = numpy.fromiter(codecs.open('new.txt', encoding='utf-8'), dtype='<U2')", "test_start": "\nimport numpy\nimport codecs\nimport numpy as np\n\ndef check(candidate):", "test": ["\n    with open ('new.txt', 'a', encoding='utf-8') as f:\n        f.write('\u091f')\n        f.write('\u091c')\n    arr = candidate()\n    assert arr[0] == '\u091f\u091c'\n"], "entry_point": "f_6375343", "intent": "load data containing `utf-8` from file `new.txt` into numpy array `arr`", "library": "numpy", "api": "np.loadtxt"}
{"task_id": 37080612, "prompt": "def f_37080612(df):\n\treturn ", "suffix": "", "canonical_solution": "df.loc[df[0].str.contains('(Hel|Just)')]", "test_start": "\nimport pandas as pd \n\ndef check(candidate):", "test": ["\n    df = pd.DataFrame([['Hello', 'World'], ['Just', 'Wanted'], ['To', 'Say'], ['I\\'m', 'Tired']])\n    df1 = candidate(df)\n    assert df1[0][0] == 'Hello'\n    assert df1[0][1] == 'Just'\n"], "entry_point": "f_37080612", "intent": "get rows of dataframe `df` that match regex '(Hel|Just)'", "library": "pandas", "api": "df[df['column_name'].str.contains('(Hel|Just)')]"}
{"task_id": 18684076, "prompt": "def f_18684076():\n\treturn ", "suffix": "", "canonical_solution": "[d.strftime('%Y%m%d') for d in pandas.date_range('20130226', '20130302')]", "test_start": "\nimport pandas \n\ndef check(candidate):", "test": ["\n    assert candidate() == ['20130226', '20130227', '20130228', '20130301', '20130302']\n"], "entry_point": "f_18684076", "intent": "create a list of date string in 'yyyymmdd' format with Python Pandas from '20130226' to '20130302'", "library": "pandas", "api": "pd.date_range"}
{"task_id": 36402748, "prompt": "def f_36402748(df):\n\treturn ", "suffix": "", "canonical_solution": "df.groupby('prots').sum().sort_values('scores', ascending=False)", "test_start": "\nimport pandas as pd \n\ndef check(candidate):", "test": ["\n    COLUMN_NAMES = [\"chemicals\", \"prots\", \"scores\"]\n    data = [[\"chemical1\", \"prot1\", 100],[\"chemical2\", \"prot2\", 50],[\"chemical3\", \"prot1\", 120]]\n    df = pd.DataFrame(data, columns = COLUMN_NAMES)\n    assert candidate(df).to_dict() == {'scores': {'prot1': 220, 'prot2': 50}}\n"], "entry_point": "f_36402748", "intent": "sort a Dataframe `df` by the total ocurrences in a column 'scores' group by 'prots'", "library": "pandas", "api": "df.sort_values"}
{"task_id": 20107570, "prompt": "def f_20107570(df, filename):\n\t", "suffix": "\n\treturn ", "canonical_solution": "df.to_csv(filename, index=False)", "test_start": "\nimport pandas as pd\n\ndef check(candidate):", "test": ["\n    file_name = 'a.csv'\n    df = pd.DataFrame([1, 2, 3], columns = ['Vals'])\n    candidate(df, file_name)\n    with open (file_name, 'r') as f:\n        lines = f.readlines()\n    assert len(lines) == 4\n"], "entry_point": "f_20107570", "intent": "write dataframe `df`, excluding index, to a csv file `filename`", "library": "pandas", "api": "df.to_csv"}
{"task_id": 38081866, "prompt": "def f_38081866():\n\treturn ", "suffix": "", "canonical_solution": "os.system('powershell.exe', 'script.ps1')", "test_start": "\nimport os\nfrom unittest.mock import Mock\n\ndef check(candidate):", "test": ["\n    os.system = Mock()\n    try:\n        candidate()\n        assert True\n    except:\n        assert False\n"], "entry_point": "f_38081866", "intent": "execute script 'script.ps1' using 'powershell.exe' shell", "library": "os", "api": "os.system"}
{"task_id": 17794266, "prompt": "def f_17794266(x):\n\treturn ", "suffix": "", "canonical_solution": "max(x.min(), x.max(), key=abs)", "test_start": "\nimport numpy as np \n\ndef check(candidate):", "test": ["\n    x = np.matrix([[1, 1], [2, -3]])\n    assert candidate(x) == -3\n"], "entry_point": "f_17794266", "intent": "get the highest element in absolute value in a numpy matrix `x`", "library": "numpy", "api": "np.max"}
{"task_id": 7635237, "prompt": "def f_7635237(a):\n\treturn ", "suffix": "", "canonical_solution": "a[:, (np.newaxis)]", "test_start": "\nimport numpy as np \n\ndef check(candidate):", "test": ["\n    data = np.array([[[5, 10, 30, 24, 100], [1, 9, 25, 49, 81]],\n            [[15, 10, 10, 16, 70], [10, 1, 25, 11, 19]],\n            [[34, 20, 10, 10, 30], [9, 20, 25, 30, 80]]])\n    assert candidate(data).tolist() == [[[[  5,  10,  30,  24, 100],\n         [  1,   9,  25,  49,  81]]],\n       [[[ 15,  10,  10,  16,  70],\n         [ 10,   1,  25,  11,  19]]],\n       [[[ 34,  20,  10,  10,  30],\n         [  9,  20,  25,  30,  80]]]]\n"], "entry_point": "f_7635237", "intent": "add a new axis to array `a`", "library": "numpy", "api": "np.newaxis"}
